{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global list_of_dataframes \n",
    "list_of_dataframes = []\n",
    "\n",
    "\n",
    "html_element = \"table.outlinetable:nth-child(10)\"\n",
    "page = requests.get(\"https://cloford.com/resources/codes/index.htm\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "tables = soup.find_all('table',class_='outlinetable')\n",
    "print(f'There were {len(tables)} tables found:\\n')\n",
    "\n",
    "for each_table in tables:\n",
    "    translate_table_to_dataframe(each_table)\n",
    "\n",
    "names = [\"Country Codes\", \"Additional Codes\", \"Additional FIPS 10-4 Codes\"]\n",
    "for one_dataframe, one_name in zip(list_of_dataframes, names):\n",
    "    one_dataframe.name = one_name\n",
    "    print(one_dataframe.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_table_to_dataframe(table):\n",
    "    dataframe_friendly_array = []\n",
    "    dataframe_ready_headers = []\n",
    "    column_headers = table.find_all('th')\n",
    "    for header in column_headers:\n",
    "        dataframe_ready_headers.append(header.text)\n",
    "\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    for row in rows:\n",
    "        row_data = []\n",
    "        for col in row.find_all('td'):\n",
    "            try:\n",
    "                row_data.append(col.text)\n",
    "            except:\n",
    "                continue\n",
    "        dataframe_friendly_array.append(row_data)\n",
    "            \n",
    "    dataframe = pd.DataFrame(data = dataframe_friendly_array, columns = dataframe_ready_headers)\n",
    "    list_of_dataframes.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [list_of_dataframes[i] for i in range(3)]\n",
    "\n",
    "final = pd.concat(df_list).drop(index=0)\n",
    "\n",
    "remove_list = ['-', '--', '\\xa0', np.nan]\n",
    "\n",
    "for column in final.columns:\n",
    "    \n",
    "    final.loc[final[column].isin(remove_list), column] = 'No Record'\n",
    "\n",
    "final.to_csv('GeoInformation_Country.csv', index = False)\n",
    "\n",
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web-scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
