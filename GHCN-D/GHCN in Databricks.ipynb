{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef56b784-fafb-4b85-a8ff-876a6aa0a3e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Read GHCN-daily data from azure blob storage URL into pandas dataframe,\\\n",
    "improve date time format, and write it into `ghcn_{year}`table\n",
    "- Modify `start_year` and `end_year` to fetch all yearly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f7ad617-5ab3-45eb-bfbc-ab3bd760f3c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "new_columns = ['ID', 'Time', 'Element', 'Value', 'M-Flag', 'Q-Flag', 'S-Flag', 'OBS-Time']\n",
    "\n",
    "start_year = 2022\n",
    "end_year = 2022\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    \n",
    "    URL = f'https://ghcn.blob.core.windows.net/ghcn/csv/daily/by_year/{year}.csv'\n",
    "\n",
    "    df = pd.read_csv(URL, names = new_columns)\n",
    "    \n",
    "    df['Time'] = pd.to_datetime(df.Time, format='%Y%m%d')\n",
    "    \n",
    "    spark.createDataFrame(df).write.mode(\"overwrite\").saveAsTable(f\"ghcn.ghcn_{year}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17acc52d-faea-42e6-a9bb-c3194babc973",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In SQL Queries, join GHCN and station_metadata and filter countries you are interested in\n",
    "- Precipitation data in year 2022 from weather stations in Central and South America "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57df898f-81b3-41c4-a011-6192355b04e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT g.Time, g.ID, s.Country, s.StationName, g.Element, g.Value\n",
    "FROM ghcn.ghcn_2022 g\n",
    "JOIN ghcn.station_metadata s\n",
    "ON g.ID = s.ID \n",
    "WHERE (s.Country IN (\"Belize\", \"Costa Rica\", \"El Salvador\", \"Guatemala\", \"Honduras\", \"Mexico\", \"Nicaragua\", \"Panama\", \"Argentina\", \"Bolivia\", \"Brazil\", \"Chile\", \"Colombia\", \"Ecuador\", \"French Guiana\", \"Guyana\", \"Paraguay\", \"Peru\", \"Suriname\", \"Uruguay\", \"Venezuela\")) AND (g.Element == 'PRCP')\n",
    "SORT BY g.Time"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2566475523215438,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "GHCN in Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
