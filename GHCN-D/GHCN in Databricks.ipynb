{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9e486c2-205b-4f5d-8588-7ded516b3f08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS ghcn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92251128-b349-406f-baf5-b5b1576f1789",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "station_metadata = pd.read_csv('station_metadata.csv')\n",
    "\n",
    "spark.createDataFrame(station_metadata).write.mode(\"overwrite\").saveAsTable(\"ghcn.station_metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef56b784-fafb-4b85-a8ff-876a6aa0a3e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Read GHCN-daily data from azure blob storage URL into pandas dataframe,\\\n",
    "improve date time format, and write it into `ghcn_{year}`table\n",
    "- Modify `start_year` and `end_year` to fetch all yearly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f7ad617-5ab3-45eb-bfbc-ab3bd760f3c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_columns = ['ID', 'Time', 'Element', 'Value', 'M-Flag', 'Q-Flag', 'S-Flag', 'OBS-Time']\n",
    "\n",
    "start_year = 2022\n",
    "end_year = 2022\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    \n",
    "    URL = f'https://ghcn.blob.core.windows.net/ghcn/csv/daily/by_year/{year}.csv'\n",
    "\n",
    "    df = pd.read_csv(URL, names = new_columns)\n",
    "    \n",
    "    df['Time'] = pd.to_datetime(df.Time, format='%Y%m%d')\n",
    "    \n",
    "    spark.createDataFrame(df).write.mode(\"overwrite\").saveAsTable(f\"ghcn.ghcn_{year}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17acc52d-faea-42e6-a9bb-c3194babc973",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In SQL Queries, join GHCN and station_metadata and filter countries you are interested in\n",
    "- Daily data in year 2022 from weather stations in Central and South America "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57df898f-81b3-41c4-a011-6192355b04e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT date(g.Time), g.ID, s.Country, s.Region, s.StationName, g.Element, g.Value\n",
    "FROM ghcn.ghcn_2022 g\n",
    "JOIN ghcn.station_metadata s\n",
    "ON g.ID = s.ID \n",
    "WHERE s.Region IN ('Central America', 'South America')\n",
    "ORDER BY g.Time, g.ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ed0b654-e7b3-412c-b646-a44e48d17c58",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- Aggregated monthly precipitation data from weather stations in Central and South America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b97c434-848e-44f1-857b-03d1680f57e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT DISTINCT month(g.Time) as Month, round(mean(g.Value) / 10, 2) as Precipitation\n",
    "FROM ghcn.ghcn_2022 g\n",
    "JOIN ghcn.station_metadata s\n",
    "ON g.ID = s.ID \n",
    "WHERE s.Region IN ('Central America', 'South America') AND g.Element == 'PRCP'\n",
    "GROUP BY Month\n",
    "ORDER BY Month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ca2ab6f-ef3a-4ba9-9074-3431d2b4beb4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- Aggregated daily average temperature data from weather stations in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5fe3931-e8b6-4592-97e1-cfa56f6d1dd8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT DISTINCT date(g.Time) as Date, round(mean(g.Value) / 10, 2) as AvgTemperature\n",
    "FROM ghcn.ghcn_2022 g\n",
    "JOIN ghcn.station_metadata s\n",
    "ON g.ID = s.ID \n",
    "WHERE s.Region = 'North America' AND g.Element = 'TAVG'\n",
    "GROUP BY Date\n",
    "ORDER BY Date"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 997443288320193,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "GHCN in Databricks",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
