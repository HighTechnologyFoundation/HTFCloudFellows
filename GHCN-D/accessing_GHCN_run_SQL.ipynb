{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b41bb4c2-7921-497b-ba31-666234435ddd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Accessing GHCN-D in Databricks\n",
    "\n",
    "### This notebook provides a quick overview of accessing GHCN - Daily data from Azure Blob Storage URL in Databricks. It then demonstrates some examples of writing queries to interact with the data stored in tables and come up with visualizations.\n",
    "\n",
    "[References for the GHCN-D metadata](https://github.com/awslabs/open-data-docs/tree/main/docs/noaa/noaa-ghcn)\n",
    "\n",
    "### Requirements:\n",
    "- Run `station_metadata_processing.ipynb` to have the table `station_metadata` in schema `ghcn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c41f1d8a-8e41-4051-8e37-6dbee96253b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1. Add `start_year` and `end_year` parameters for job workflows usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7893ccd-cbb9-4f57-ba34-024a8f2b4f9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"start_year\", \"\")\n",
    "dbutils.widgets.text(\"end_year\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef56b784-fafb-4b85-a8ff-876a6aa0a3e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2. Accessing GHCN-D data\n",
    "- Read GHCN-daily data from azure blob storage URL into pandas dataframe\n",
    "- drop rows that have quality check issue\n",
    "- improve date time format\n",
    "- write it into `ghcn.ghcn_{year}`table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f7ad617-5ab3-45eb-bfbc-ab3bd760f3c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "new_columns = ['ID', 'Time', 'Element', 'Value', 'M-Flag', 'Q-Flag', 'S-Flag', 'OBS-Time']\n",
    "\n",
    "for year in range(int(dbutils.widgets.get(\"start_year\")), int(dbutils.widgets.get(\"end_year\")) + 1):\n",
    "    \n",
    "    URL = f'https://ghcn.blob.core.windows.net/ghcn/csv/daily/by_year/{year}.csv'\n",
    "\n",
    "    df = pd.read_csv(URL, names = new_columns)\n",
    "\n",
    "    df.drop(df[df['Q-Flag'].notnull() == True].index, inplace=True)\n",
    "    \n",
    "    df['Time'] = pd.to_datetime(df.Time, format='%Y%m%d')\n",
    "    \n",
    "    spark.createDataFrame(df).write.mode(\"overwrite\").saveAsTable(f\"ghcn.ghcn_{year}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a68301de-ab54-49d7-8a8d-f3a76495bad2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Query and Process the results into `ghcn_pivot_{end_year}` table for dynamic dashboard usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "249d0bb6-f497-4b9c-bc3c-71998888c949",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# query the data in US and specific climate attributes\n",
    "merge_df = spark.sql(f'select date(g.Time), g.Element, mean(g.Value) as Value\\\n",
    "                              from ghcn.ghcn_{dbutils.widgets.get(\"end_year\")} g\\\n",
    "                              join ghcn.station_metadata s\\\n",
    "                              on g.ID = s.ID\\\n",
    "                              where s.FIPS == \"US\" and g.Element in (\"PRCP\", \"SNOW\", \"SNWD\", \"TMAX\", \"TMIN\", \"TAVG\", \"AWND\")\\\n",
    "                              group by g.Time, g.Element\\\n",
    "                              order by g.Time')\n",
    "\n",
    "# using `pivot_table()` to reshape the result\n",
    "merge_df = merge_df.toPandas()\n",
    "pivot_df = merge_df.pivot_table(index = 'Time', columns = 'Element', values = 'Value').reset_index().rename_axis(None, axis=1)\n",
    "spark.createDataFrame(pivot_df).write.mode(\"overwrite\").saveAsTable(f'ghcn.ghcn_pivot_{dbutils.widgets.get(\"end_year\")}')\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17acc52d-faea-42e6-a9bb-c3194babc973",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3. In SQL, join `ghcn.station_metadata` and `ghcn.ghcn_{year}` tables to query the results you are interested in\n",
    "- Aggregated monthly precipitation data from weather stations in Central and South America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b97c434-848e-44f1-857b-03d1680f57e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT DISTINCT month(g.Time) as Month, round(mean(g.Value) / 10, 2) as Precipitation\n",
    "FROM ghcn.ghcn_${end_year} g\n",
    "JOIN ghcn.station_metadata s\n",
    "ON g.ID = s.ID \n",
    "WHERE s.Region IN ('Central America', 'South America') AND g.Element == 'PRCP'\n",
    "GROUP BY Month\n",
    "ORDER BY Month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ca2ab6f-ef3a-4ba9-9074-3431d2b4beb4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- Aggregated daily average temperature data from weather stations in North America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5fe3931-e8b6-4592-97e1-cfa56f6d1dd8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT DISTINCT date(g.Time) as Date, round(mean(g.Value) / 10, 2) as AvgTemperature\n",
    "FROM ghcn.ghcn_${end_year} g\n",
    "JOIN ghcn.station_metadata s\n",
    "ON g.ID = s.ID \n",
    "WHERE s.Region = 'North America' AND g.Element = 'TAVG'\n",
    "GROUP BY Date\n",
    "ORDER BY Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d8687a3-9513-44d4-b637-0f50e692dbe1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- Temperature map in July `end_year` in the United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ca6dc0c-22d5-4b52-bff9-00722d7938d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT s.State, round(mean(g.Value) / 10, 2) as AvgTemperature\n",
    "FROM ghcn.ghcn_${end_year} g\n",
    "JOIN ghcn.station_metadata s\n",
    "ON g.ID = s.ID \n",
    "WHERE s.FIPS == 'US' AND g.Element = 'TAVG' AND month(g.Time) == '5'\n",
    "GROUP BY s.State\n",
    "ORDER BY s.State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af19b287-0598-4943-b6a9-efd9e99e9d3a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- Temperature map in Jan `end_year` in the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2694bfb8-1f1c-4b91-a3d7-d8c0e23e9e1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT s.`ISO-2`, round(mean(g.Value) / 10, 2) as AvgTemperature\n",
    "FROM ghcn.ghcn_${end_year} g\n",
    "JOIN ghcn.station_metadata s\n",
    "ON g.ID = s.ID \n",
    "WHERE g.Element = 'TAVG' AND month(g.Time) == '1'\n",
    "GROUP BY s.`ISO-2`"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2712572252342699,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "accessing_GHCN_run_SQL",
   "widgets": {
    "end_year": {
     "currentValue": "2023",
     "nuid": "33903582-cf28-4b55-8c47-708b1f149fd3",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "end_year",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "start_year": {
     "currentValue": "2023",
     "nuid": "86b89d73-f5d8-4a0c-a7cb-73218c546da2",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "start_year",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
