{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ce4999",
   "metadata": {},
   "source": [
    "# Ways of accessing data in National Solar Radiation Database using Python\n",
    "\n",
    "### This notebook shows five ways to access NSRDB data including:\n",
    "- Three cloud service providers:\n",
    "    - Azure Blob Storage\n",
    "    - AWS S3 Buckets\n",
    "    - Google Cloud Storage\n",
    "- NREL developer API\n",
    "- [AWS HDF Group's Highly Scalable Data Service (HSDS)](https://github.com/NREL/hsds-examples/blob/master/notebooks/03_NSRDB_introduction.ipynb)\n",
    "\n",
    "This notebook gives example code for each of the 3 CSPs and the NREL API.  The HSDS access is shown in the link above.\n",
    "\n",
    "Each of the CSP data access demonstrations request the same H5 datafile related to the Philippines.  This is for a consistent comparison of the three providers.\n",
    "\n",
    "### Things to know:\n",
    "-  Original files at NSRDB are stored in `.h5` format, which is one of the Hierarchical Data Formats (HDF) used to store large amount of data. In order to access it from python, `xarray` is a good package with backend engine `h5netcdf` to open the file. \n",
    "\n",
    "- Data is available on three main Cloud Service Providers. To access them, we will utilize their `FileSystems` with valid URI to open the data files. \n",
    "\n",
    "- The following packages need to be installed into your python environment for the examples to execute: \n",
    "    - `adlfs`\n",
    "    - `xarray`\n",
    "    - `planetary_computer`\n",
    "    - `s3fs`\n",
    "    - `gcsfs`\n",
    "    - `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc685dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing this cell will install the required packages for the notebook\n",
    "# NOTE: this only need to be run once per machine / account\n",
    "%pip install adlfs\n",
    "%pip install \"xarray[complete]\"\n",
    "%pip install planetary_computer\n",
    "%pip install s3fs\n",
    "%pip install gcsfs\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2bbf28",
   "metadata": {},
   "source": [
    "---\n",
    "## Azure Blob Storage\n",
    "\n",
    "- Use `planetary_computer` to get token to access\n",
    "- Use `AzureBlobFileSystem` to access files in Azure Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527ec50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import planetary_computer\n",
    "from adlfs import AzureBlobFileSystem\n",
    "\n",
    "# file parameters\n",
    "storage_account_name = 'nrel'\n",
    "\n",
    "fs = AzureBlobFileSystem(\n",
    "    account_name = storage_account_name,\n",
    "    credential = planetary_computer.sas.get_token(\"nrel\", \"nrel-nsrdb\").token\n",
    ")\n",
    "\n",
    "file = fs.open(f\"nrel-nsrdb/philippines/philippines_2017.h5\")\n",
    "AZ_ds = xr.open_dataset(file, backend_kwargs={\"phony_dims\": \"sort\"}, engine=\"h5netcdf\")\n",
    "AZ_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb994b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## AWS S3 Bucket\n",
    "\n",
    "Use `s3fs` to allow python to access the AWS S3 buckets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b00b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import s3fs \n",
    "\n",
    "NSRDB_S3_URI = \"s3://nrel-pds-nsrdb/philippines/philippines_2017.h5\"\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "AWS_ds = xr.open_dataset(fs.open(NSRDB_S3_URI), backend_kwargs={\"phony_dims\": \"sort\"}, engine='h5netcdf')\n",
    "AWS_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6331123",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Google Cloud Storage\n",
    "\n",
    "- [Install the gcloud CLI](https://cloud.google.com/sdk/docs/install)\n",
    "    - Use the link above and follow the directions for installing Google Cloud CLI.\n",
    "    - Use the default values for options, if at all possible.\n",
    "- Create a free trial of Google Cloud.  This will require the use of a credit card, but it will not be charged until after the trial AND you accept the possibility of charges.\n",
    "- In Google Cloud, create a new project. This can be named anything you like within the naming conventions of Google Cloud. This project will be referenced later in this notebook.\n",
    "\n",
    "*NOTE: At this point, for Jupyter to recognize the installation of the Google Cloud package, it may be necessary to restart your Jupyter environment.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd328290",
   "metadata": {},
   "source": [
    "#### Initialize your Google Cloud access\n",
    "- From a PowerShell window, execute the following: ```gcloud init```\n",
    "    - Select your Google account and the project you created earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556a80b",
   "metadata": {},
   "source": [
    "#### Authorize your cloud account to access the NSRDB resources\n",
    "When executing the following cell, you will be prompted for your Google Cloud login in your default browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b550298",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90af360",
   "metadata": {},
   "source": [
    "#### Use `gcsfs` to allow python access to Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45474f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "\n",
    "NSRDB_GCS_URI = \"gs://nsrdb-netcdf/philippines/philippines_2017.h5\"\n",
    "fs = gcsfs.GCSFileSystem(anon=True)\n",
    "\n",
    "tempFile = fs.open(NSRDB_GCS_URI)\n",
    "\n",
    "GCS_ds = xr.open_dataset(tempFile, backend_kwargs={\"phony_dims\": \"sort\"}, engine='h5netcdf')\n",
    "GCS_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c03e6",
   "metadata": {},
   "source": [
    "## Small conclusion and observation:\n",
    "Based on the results above, there are several trade offs when accessing data from three different cloud service providers. AWS has the least configurations and no token is needed, but it took a little bit longer to read the data. In comparison, Azure and Google cloud requires more configuration but with faster speed of accessing the data. Therefore, end users should take all these factors into account when choosing which cloud service provider to use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c71de6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### NREL developer Python API\n",
    "Use the National Renewable Energy Lab's API to access the data\n",
    "\n",
    "- Get NSRDB API Key: https://developer.nrel.gov/signup/\n",
    "    - You will need to copy your API key and personal information into the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b008e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You must request an NSRDB api key from the link above\n",
    "api_key = <your api key>\n",
    "# Your full name, use '+' instead of spaces.\n",
    "your_name = <your name>\n",
    "# Your reason for using the NSRDB, (e.g., 'research', 'commercial', 'education', 'non+profit', 'beta+testing')\n",
    "reason_for_use = <your reason>\n",
    "# Your affiliation\n",
    "your_affiliation = <your affiliation>\n",
    "# Your email address\n",
    "your_email = <your email>\n",
    "# Join the NREL email list?\n",
    "mailing_list = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544151bb",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "\n",
    "- Data download format is `.csv`\n",
    "- Use `Pandas` to read it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Declare all variables as strings. Spaces must be replaced with '+', i.e., change 'John Smith' to 'John+Smith'.\n",
    "# Define the lat, long of the location\n",
    "lat, lon = 39.2606, -80.1139\n",
    "\n",
    "# Specify Coordinated Universal Time (UTC), 'true' will use UTC, 'false' will use the local time zone of the data.\n",
    "# NOTE: In order to use the NSRDB data in SAM, you must specify UTC as 'false'. SAM requires the data to be in the\n",
    "# local time zone.\n",
    "utc = 'false'\n",
    "\n",
    "# Set the attributes to extract (e.g., dhi, ghi, etc.), separated by commas.\n",
    "attributes = 'ghi,dhi,dni,wind_speed,air_temperature,solar_zenith_angle'\n",
    "# Choose year of data\n",
    "year = '2019'\n",
    "# Set leap year to true or false. True will return leap day data if present, false will not.\n",
    "leap_year = 'false'\n",
    "# Set time interval in minutes, i.e., '30' is half hour intervals. Valid intervals are 30 & 60.\n",
    "interval = '30'\n",
    "\n",
    "\n",
    "# Declare url string\n",
    "url = 'https://developer.nrel.gov/api/nsrdb/v2/solar/psm3-download.csv?' \\\n",
    "    f'wkt=POINT({lon}%20{lat})&names={year}&leap_day={leap_year}&interval={interval}&utc={utc}&' \\\n",
    "    f'full_name={your_name}&email={your_email}&affiliation={your_affiliation}&mailing_list={mailing_list}&' \\\n",
    "    f'reason={reason_for_use}&api_key={api_key}&attributes={attributes}'\n",
    "# Return all but first 2 lines of csv to get data:\n",
    "df = pd.read_csv(url, skiprows=2)\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
