{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ce4999",
   "metadata": {},
   "source": [
    "# Ways of accessing data in National Solar Radiance Database using Python\n",
    "\n",
    "### This notebook documents five ways to access data in NSRDB including:\n",
    "- Three cloud service providers:\n",
    "    - Azure Blob Storage\n",
    "    - AWS S3 Buckets\n",
    "    - Google Cloud Storage\n",
    "- NREL developer API\n",
    "- [AWS HDF Group's Highly Scalable Data Service (HSDS)](https://github.com/NREL/hsds-examples/blob/master/notebooks/03_NSRDB_introduction.ipynb)\n",
    "\n",
    "### Things to know:\n",
    "-  Original files in NSRDB are stored in `.h5` format, which is one of the Hierarchical Data Formats (HDF) used to store large amount of data. In order to access it, `xarray` is a good package with backend engine `h5netcdf` to open the file. \n",
    "\n",
    "- Data is available on three main Cloud Service Providers. To access them, utilize their `FileSystem` with valid URI to open it. \n",
    "\n",
    "- The following packages need to be installed into your python environment: \n",
    "    - `adlfs`  `xarray`  `planetary_computer`  `s3fs`  `gcsfs`  `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc685dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing this cell will install the required packages for the notebook\n",
    "%pip install adlfs\n",
    "%pip install \"xarray[complete]\"\n",
    "%pip install planetary_computer\n",
    "%pip install s3fs\n",
    "%pip install gcsfs\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2bbf28",
   "metadata": {},
   "source": [
    "---\n",
    "### Azure Blob Storage\n",
    "\n",
    "- using `planetary_computer` to get token to access\n",
    "- using `AzureBlobFileSystem` to access files in Azure Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527ec50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import planetary_computer\n",
    "from adlfs import AzureBlobFileSystem\n",
    "\n",
    "# file parameters\n",
    "year = 2020\n",
    "storage_account_name = 'nrel'\n",
    "\n",
    "fs = AzureBlobFileSystem(\n",
    "    account_name = storage_account_name,\n",
    "    credential = planetary_computer.sas.get_token(\"nrel\", \"nrel-nsrdb\").token\n",
    ")\n",
    "\n",
    "file = fs.open(f\"nrel-nsrdb/v3/nsrdb_{year}.h5\")\n",
    "AZ_ds = xr.open_dataset(file, backend_kwargs={\"phony_dims\": \"sort\"}, engine=\"h5netcdf\")\n",
    "AZ_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb994b",
   "metadata": {},
   "source": [
    "### AWS S3 Bucket\n",
    "\n",
    "Using `s3fs` to allow python access to the AWS S3 buckets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b00b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import s3fs \n",
    "\n",
    "NSRDB_S3_URI = \"s3://nrel-pds-nsrdb/philippines/philippines_2017.h5\"\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "AWS_ds = xr.open_dataset(fs.open(NSRDB_S3_URI), backend_kwargs={\"phony_dims\": \"sort\"}, engine='h5netcdf')\n",
    "AWS_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6331123",
   "metadata": {},
   "source": [
    "### Google Cloud Storage\n",
    "\n",
    "- [Install the gcloud CLI](https://cloud.google.com/sdk/docs/install)\n",
    "- run `!gcloud auth application-default login` to get authentication\n",
    "- Using `gcsfs` to allow python access to Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45474f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "\n",
    "NSRDB_GCS_URI = \"gs://nsrdb-netcdf/philippines/philippines_2017.h5\"\n",
    "fs = gcsfs.GCSFileSystem(anon=True)\n",
    "\n",
    "GCS_ds = xr.open_dataset(fs.open(NSRDB_GCS_URI), backend_kwargs={\"phony_dims\": \"sort\"}, engine='h5netcdf')\n",
    "GCS_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c71de6",
   "metadata": {},
   "source": [
    "### NREL developer Python API\n",
    "\n",
    "- Get NSRDB API Key: https://developer.nrel.gov/signup/\n",
    "- Data downloaded format is `.csv`\n",
    "- Use `Pandas` to read it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Declare all variables as strings. Spaces must be replaced with '+', i.e., change 'John Smith' to 'John+Smith'.\n",
    "# Define the lat, long of the location\n",
    "lat, lon = 39.2606, -80.1139\n",
    "# You must request an NSRDB api key from the link above\n",
    "api_key = {your api key}\n",
    "# Set the attributes to extract (e.g., dhi, ghi, etc.), separated by commas.\n",
    "attributes = 'ghi,dhi,dni,wind_speed,air_temperature,solar_zenith_angle'\n",
    "# Choose year of data\n",
    "year = '2019'\n",
    "# Set leap year to true or false. True will return leap day data if present, false will not.\n",
    "leap_year = 'false'\n",
    "# Set time interval in minutes, i.e., '30' is half hour intervals. Valid intervals are 30 & 60.\n",
    "interval = '30'\n",
    "# Specify Coordinated Universal Time (UTC), 'true' will use UTC, 'false' will use the local time zone of the data.\n",
    "# NOTE: In order to use the NSRDB data in SAM, you must specify UTC as 'false'. SAM requires the data to be in the\n",
    "# local time zone.\n",
    "utc = 'false'\n",
    "# Your full name, use '+' instead of spaces.\n",
    "your_name = 'Justin+Lin'\n",
    "# Your reason for using the NSRDB.\n",
    "reason_for_use = 'beta+testing'\n",
    "# Your affiliation\n",
    "your_affiliation = 'HTF'\n",
    "# Your email address\n",
    "your_email = 'slin@wvhtf.org'\n",
    "# Please join our mailing list so we can keep you up-to-date on new developments.\n",
    "mailing_list = 'false'\n",
    "\n",
    "# Declare url string\n",
    "url = 'https://developer.nrel.gov/api/nsrdb/v2/solar/psm3-download.csv?wkt=POINT({lon}%20{lat})&names={year}&leap_day={leap}&interval={interval}&utc={utc}&full_name={name}&email={email}&affiliation={affiliation}&mailing_list={mailing_list}&reason={reason}&api_key={api}&attributes={attr}'.format(year=year, lat=lat, lon=lon, leap=leap_year, interval=interval, utc=utc, name=your_name, email=your_email, mailing_list=mailing_list, affiliation=your_affiliation, reason=reason_for_use, api=api_key, attr=attributes)\n",
    "# Return all but first 2 lines of csv to get data:\n",
    "df = pd.read_csv(url, skiprows=2)\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
