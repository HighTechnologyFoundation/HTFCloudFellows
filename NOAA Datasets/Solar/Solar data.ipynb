{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar energy related datasets \n",
    "\n",
    "### 1. **National Solar Radiation Database (`NSRDB`)**: a high temporal and spatial resolution dataset consisting of the three most widely used measurements of solar radiation—global horizontal, direct normal, and diffuse horizontal irradiance—as well as other meteorological data. [More information about NSRDB data](https://nsrdb.nrel.gov/about/what-is-the-nsrdb)\n",
    "- Physical Solar Model (PSM) version 3:\n",
    "    - Region: USA (Continental) & Mexico\n",
    "    - Time Covered: 2018 - 2022\n",
    "    - Temporal Resolution: 5 mins\n",
    "    - Spatial Resolution: 2 X 2 km\n",
    "    - Data Access: NREL endpoint API, NREL HSDS Server, Azure, AWS, GCS\n",
    "\n",
    "### 2. **The Super-Resolution for Renewable Energy Resource Data with Climate Change Impacts (`Sup3rCC`)** : a collection of 4km hourly wind, solar, temperature, humidity, and pressure fields for the contiguous United States under various climate change scenarios. It utilizes a generative machine learning approach called Sup3r (Super-Resolution for Renewable Energy Resource Data) to downscale Global Climate Model (GCM) data. [More information about Sup3rCC](https://www.nrel.gov/analysis/sup3rcc.html)\n",
    "- Region: Contiguous United States\n",
    "- Time Covered: 2015 - 2059\n",
    "- Temporal Resolution: 60 mins\n",
    "- Spatial Resolution: 4km\n",
    "- Data Access: AWS, NREL HSDS Server\n",
    "### 3. **`Solcast`** is a private company dedicated in generating live and forecast solar datasets globally in high temporal and spatial resolution. It provides API toolkit for people to access the data at no cost by creating an account with no credit card required. [More information about Solcast](https://solcast.com/)\n",
    "- Historical data:\n",
    "    - Region: Global (note: far ocean and polar regions are coarser resolution)\n",
    "    - Time Covered: January 2007 to 7 days ago\n",
    "    - Temporal Resolution: 5, 10, 15, 30 & 60 minutes (period-mean values)\n",
    "    - Spatial Resolution: 90 meters \n",
    "    - Data Access: Solcast Web Toolkit and Solcast API\n",
    "        - Solcast Python SDK: https://solcast.github.io/solcast-api-python-sdk/ \n",
    "- Live and Forecast data:\n",
    "    - Region: Global (note: far ocean and polar regions are coarser resolution)\n",
    "    - Time Covered: -7 days to +14 days\n",
    "    - Temporal Resolution: 5, 10, 15, 20, 30 & 60 minutes (period-mean values)\n",
    "    - Spatial Resolution: 90 meters \n",
    "    - Data Access: Solcast Web Toolkit and Solcast API\n",
    "\n",
    "---\n",
    "\n",
    "## This notebook demonstrates ways of accessing different solar related datasets that uses the `First Energy Fort Martin Solar Site` as an example:\n",
    "- Latitude: 39.75 N\n",
    "- Longitude: -79.95 W\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following examples require these libraries/packages to be installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install s3path\n",
    "!pip install alive-progress\n",
    "!pip install pysam\n",
    "!pip install xarray\n",
    "!pip install --user solcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### NSRDB Demonstration\n",
    "- Year 2022\n",
    "- Fort Martin Site\n",
    "- 5 mins temporal resolution\n",
    "- **API Key needed**: https://developer.nrel.gov/signup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import numpy as np\n",
    "import PySAM.PySSC as pssc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from typing import List\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "# url parameters\n",
    "# the lat and long for the Fort Martin solar site\n",
    "lat = 39.75\n",
    "lon = -79.95\n",
    "\n",
    "interval = 5\n",
    "leap_year = 'false'\n",
    "utc = 'false'\n",
    "mailing_list = 'false'\n",
    "api_key = \"Your_API_Key\"\n",
    "your_name = \"Justin+Lin\"\n",
    "reason_for_use = \"Research\"\n",
    "your_affiliation = \"HTF\"\n",
    "your_email = \"slin@wvhtf.org\"\n",
    "dataset = \"psm3-5min-download\"\n",
    "attributes = \"\"\n",
    "\n",
    "def Get_URLs_From_NSRDB(start_year:int, end_year = None) -> List[str]:\n",
    "    UrlList = []\n",
    "    \n",
    "    if end_year is not None:\n",
    "        for year in range(start_year, end_year+1):\n",
    "            url = f\"https://developer.nrel.gov/api/nsrdb/v2/solar/{dataset}.csv?\"\\\n",
    "                    f\"wkt=POINT({lon}%20{lat})&names={year}&leap_day={leap_year}&interval={interval}\"\\\n",
    "                    f\"&utc={utc}&full_name={your_name}&email={your_email}&affiliation={your_affiliation}\"\\\n",
    "                    f\"&mailing_list={mailing_list}&reason={reason_for_use}&api_key={api_key}&attributes={attributes}\"\n",
    "            UrlList.append(url)\n",
    "    else: \n",
    "        url = f\"https://developer.nrel.gov/api/nsrdb/v2/solar/{dataset}.csv?\"\\\n",
    "                f\"wkt=POINT({lon}%20{lat})&names={start_year}&leap_day={leap_year}&interval={interval}\"\\\n",
    "                f\"&utc={utc}&full_name={your_name}&email={your_email}&affiliation={your_affiliation}\"\\\n",
    "                f\"&mailing_list={mailing_list}&reason={reason_for_use}&api_key={api_key}&attributes={attributes}\"\n",
    "        UrlList.append(url)\n",
    "    \n",
    "    return UrlList\n",
    "\n",
    "data_urls = Get_URLs_From_NSRDB(2022)\n",
    "FM_NSRDB_2022 = pd.read_csv(data_urls[0], low_memory=False)\n",
    "\n",
    "# print the data for the user to see\n",
    "FM_NSRDB_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sup3rCC Demonstration\n",
    "- Years 2023 to 2024\n",
    "- Monongalia County, WV (where Fort Martin solar site is located)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from s3path import S3Path\n",
    "import xarray as xr\n",
    "import s3fs\n",
    "\n",
    "# s3fs is the package used to access AWS S3 buckets\n",
    "# the data is public, no need for credentials\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "appended_data = []\n",
    "# the data covers year from 2023 to 2024\n",
    "start_year = 2023\n",
    "end_year = 2024\n",
    "# specify climate data types and attributes \n",
    "climate_type = ['solar', 'wind', 'trh', 'pressure']\n",
    "attributes = [['ghi', 'dni', 'dhi'], 'windspeed_10m', ['temperature_2m', 'relativehumidity_2m'], 'pressure_0m']\n",
    "climate_attr_dict = {climate_type: attributes for climate_type, attributes in zip(climate_type, attributes)}\n",
    "# calculate the total number in the loop\n",
    "attributes_num = len(attributes)\n",
    "year_num = len(range(start_year, end_year + 1))\n",
    "loop_total_num = year_num * attributes_num\n",
    "\n",
    "# specify the components of the S3 URI\n",
    "# cloud_type = \"s3://\"\n",
    "bucket = \"nrel-pds-sup3rcc\"\n",
    "folder = \"conus_mriesm20_ssp585_r1i1p1f1\"\n",
    "version = \"v0.1.0\"\n",
    "file_base = \"sup3rcc_conus_mriesm20_ssp585_r1i1p1f1\"\n",
    "file_extension = \"h5\"\n",
    "\n",
    "URI_base = S3Path(f'/{bucket}/{folder}/{version}/{file_base}')\n",
    "\n",
    "with alive_bar(loop_total_num, force_tty=True, title='Running', length=20, bar = 'smooth') as bar:\n",
    "\n",
    "    for climate in climate_type:\n",
    "        \n",
    "        for year in range(start_year, end_year + 1):\n",
    "            URI = f\"{URI_base.as_uri()}_{climate}_{year}.{file_extension}\"\n",
    "\n",
    "            # use `xarray` with engine `h5netcdf` to access data\n",
    "            ds = xr.open_dataset(fs.open(URI), backend_kwargs={\"phony_dims\": \"sort\"}, engine='h5netcdf') # type: ignore\n",
    "\n",
    "            time_index = pd.to_datetime(ds['time_index'][...].astype(str)) # type: ignore\n",
    "            meta = pd.DataFrame(ds.meta.data)\n",
    "            FM_site_index = meta[(meta.county == b'Monongalia') & (meta.elevation == 318)].index[0]\n",
    "            attrs = [v for k, v in climate_attr_dict.items() if climate == k][0]\n",
    "\n",
    "            # subset the data at FM site\n",
    "            if climate in ['solar', 'trh']:\n",
    "                for att in attrs:\n",
    "                    subset = ds[att][:, FM_site_index].load()\n",
    "                    data = pd.DataFrame({f\"{att}\" : subset}, index = time_index)\n",
    "                    appended_data.append(data)\n",
    "            else:\n",
    "                subset = ds[attrs][:, FM_site_index].load()\n",
    "                data = pd.DataFrame({f\"{attrs}\" : subset}, index = time_index)\n",
    "                appended_data.append(data)\n",
    "            \n",
    "            # update the progress bar\n",
    "            bar()\n",
    "\n",
    "# concatenate all the data\n",
    "FM_Sup3rCC_2023_2024 = pd.concat(appended_data)\n",
    "\n",
    "# rename the attributes with measurements\n",
    "FM_Sup3rCC_2023_2024.rename({'ghi':\"ghi (W/m2)\",\n",
    "                   'dni':'dni (W/m2)', \n",
    "                   'dhi':'dhi (W/m2)', \n",
    "                   'windspeed_10m': \"Windspeed (m/s)\", \n",
    "                   'temperature_2m': \"Temperature (C)\", \n",
    "                   'relativehumidity_2m': \"Relative Humidity (%)\",\n",
    "                   'pressure_0m': \"Pressure (hPa)\"}, axis=1, inplace=True)\n",
    "\n",
    "# adjust the scale of measurements\n",
    "FM_Sup3rCC_2023_2024[\"Temperature (C)\"] = FM_Sup3rCC_2023_2024[\"Temperature (C)\"] / 10000\n",
    "FM_Sup3rCC_2023_2024[\"Windspeed (m/s)\"] = FM_Sup3rCC_2023_2024[\"Windspeed (m/s)\"] / 10000\n",
    "FM_Sup3rCC_2023_2024[\"Relative Humidity (%)\"] = FM_Sup3rCC_2023_2024[\"Relative Humidity (%)\"] / 10000\n",
    "\n",
    "FM_Sup3rCC_2023_2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Solcast Demonstration\n",
    "- Fort Martin site: -7 days to present\n",
    "- 30 mins temporal resolution\n",
    "- **API Key needed**: https://toolkit.solcast.com.au/register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = \"Your_API_Key\"\n",
    "\n",
    "# The URL for the weather site in Solcast\n",
    "URL = f\"https://api.solcast.com.au/weather_sites/388d-25ae-c428-bcf3/estimated_actuals?format=csv&api_key={API_key}\"\n",
    "\n",
    "FM_SOLCAST_LIVE = pd.read_csv(URL)\n",
    "\n",
    "FM_SOLCAST_LIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the Fort Martin solar site\n",
    "FM_lat = 39.75\n",
    "FM_lon = -79.95\n",
    "hours = 168 # 7 days\n",
    "period = 'PT5M'\n",
    "output_parameters = 'air_temp,dni,ghi'\n",
    "azimuth = 0\n",
    "tilt = 23\n",
    "array_type = 'fixed'\n",
    "format = 'csv'\n",
    "\n",
    "url = \"https://api.solcast.com.au/data/live/radiation_and_weather?\"\\\n",
    "      f\"latitude={FM_lat}&longitude={FM_lon}&hours={hours}&period={period}&\"\\\n",
    "      f\"output_parameters{output_parameters}&azimuth={azimuth}&tilt={tilt}&\"\\\n",
    "      f\"array_type={array_type}&format={format}&api_key={API_key}\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Solcast Python SDK\n",
    "- use unmetered location 'Sydney Opera House' for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solcast import live\n",
    "from solcast.unmetered_locations import UNMETERED_LOCATIONS\n",
    "\n",
    "# use unmetered location for testing to avoid API requests consumption\n",
    "sydney = UNMETERED_LOCATIONS['Sydney Opera House']\n",
    "res = live.radiation_and_weather(\n",
    "    api_key = API_key,\n",
    "    latitude = sydney['latitude'], \n",
    "    longitude = sydney['longitude'],\n",
    "    hours = 168,\n",
    "    period = 'PT10M',\n",
    "    output_parameters = 'dni,ghi'\n",
    ")\n",
    "\n",
    "test_df = res.to_pandas()\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fort Martin site: present to +7 days\n",
    "- 30 mins temporal resolution\n",
    "- **API Key needed**: https://toolkit.solcast.com.au/register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = f\"https://api.solcast.com.au/weather_sites/388d-25ae-c428-bcf3/forecasts?format=csv&api_key={API_key}\"\n",
    "\n",
    "FM_SOLCAST_FORECAST = pd.read_csv(URL)\n",
    "\n",
    "FM_SOLCAST_FORECAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FM site: 20200101 to 20240805\n",
    "- 60 mins temporal resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This demonstration is reading a local CSV file as the the data source\n",
    "file_name = './Solcast_FortMartin_20200101_20240805.csv'\n",
    "FM_SOLCAST_HISTORIC = pd.read_csv(file_name)\n",
    "FM_SOLCAST_HISTORIC = FM_SOLCAST_HISTORIC[ ['period_end'] + [ col for col in FM_SOLCAST_HISTORIC.columns if col != 'period_end' ] ]\n",
    "FM_SOLCAST_HISTORIC.drop('period', axis=1, inplace=True)\n",
    "FM_SOLCAST_HISTORIC.rename({'period_end':'time'}, axis = 1, inplace=True)\n",
    "FM_SOLCAST_HISTORIC['time'] = pd.to_datetime(FM_SOLCAST_HISTORIC.time).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "FM_SOLCAST_HISTORIC['time'] = pd.to_datetime(FM_SOLCAST_HISTORIC.time)\n",
    "\n",
    "FM_SOLCAST_HISTORIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Solcast Historic Data Parameters Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './Solcast_Historic_Parameters_Documentation.csv'\n",
    "SOLCAST_PARAMETERS_DOC = pd.read_csv(file_name)\n",
    "SOLCAST_PARAMETERS_DOC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
