{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Global Forecast System (GFS) data from Azure public container\n",
    "\n",
    "### Product focus:\n",
    "There are five products in GFS dataset:\n",
    "- gfs: forecast data from the Global Forecast System (GFS)\n",
    "- gdas: forecast data gridded with the Global Data Assimilation System (GDAS)\n",
    "- gfsmos: model output statistics from the GFS MOS suite\n",
    "- sst: sea surface temperature forecasts produced by the NCEP Sea Surface Temperature (SST) models\n",
    "- enkfgdas: data assimilated using the GSI Hybrid/4DEnVar Data Assimilation system\n",
    "\n",
    "**This notebook only focuses on `GFS - Global longitude-latitude grid` product, with most commonly used parameters.**\n",
    "### This notebook does the following:\n",
    "- Fetch GRIB data files from Azure URLs\n",
    "- Read GRIB file into xarray dataset\n",
    "- Convert Xarray dataset to pandas dataframe\n",
    "- Create mulitiple visualizations including animations using the GFS data\n",
    "### References:\n",
    "- [NCEI Environmental Modeling Center/GFS](https://www.emc.ncep.noaa.gov/emc/pages/numerical_forecast_systems/gfs.php)\n",
    "- [GFS Products Inventory](https://www.nco.ncep.noaa.gov/pmb/products/gfs/#GFS)\n",
    "- [Azure Storage Resources](https://planetarycomputer.microsoft.com/dataset/storage/noaa-gfs)\n",
    "- [Xarray Library Documentation](https://docs.xarray.dev/en/stable/index.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell to install the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install --upgrade pip\n",
    "# %pip install xarray[complete]\n",
    "# %pip install eccodes\n",
    "# %pip install ecmwflibs\n",
    "# %pip install cfgrib\n",
    "# %pip install numpy==1.23.0\n",
    "# %pip install alive_progress\n",
    "# %pip install cartopy\n",
    "# %pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to restart the notebook if you are in the Databricks environment\n",
    "\n",
    "# dbutils.library.restartPython() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function `file_path()` to fetch the urls from a public Azure container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def file_path(cycle_runtime: int, forecast_hour: int, year: int, month: int, day: int, resolution_degree: float) -> str:\n",
    "    prefix_path = \"https://noaagfs.blob.core.windows.net/\"\n",
    "    product_name = \"gfs\"\n",
    "    resolution_split = str(resolution_degree).split(\".\")\n",
    "    file_path = (\n",
    "        f\"{product_name}/{product_name}.{year}{month:>02}{day:>02}/\"\n",
    "        f\"{cycle_runtime:>02}/atmos/{product_name}.t{cycle_runtime:>02}z.\"\n",
    "        f\"pgrb2.{resolution_split[0]}p{resolution_split[1]:<02}.f{forecast_hour:>03}\"\n",
    "    )\n",
    "    whole_path = os.path.join(prefix_path, file_path)\n",
    "\n",
    "    return whole_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function `read_into_xarray_dataset()` to read given url into Xarray dataset\n",
    "\n",
    "See `key_words.json` for filtering keywords reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "with open(\"key_words.json\") as f:\n",
    "    key_words = json.load(f)\n",
    "\n",
    "key_details = key_words[\"key_details\"]\n",
    "\n",
    "def read_into_xarray_dataset(URL: str, level: str, step: Optional[str] = None):\n",
    "    try:\n",
    "        filename, _ = urllib.request.urlretrieve(URL)\n",
    "        step_key = [\"atmosphere\", \"surface\", \"lowCloudLayer\", \"middleCloudLayer\", \"highCloudLayer\"]\n",
    "\n",
    "        if level in step_key:\n",
    "            ds = xr.open_dataset(\n",
    "                filename,\n",
    "                engine=\"cfgrib\",\n",
    "                filter_by_keys={\"typeOfLevel\": level, \"stepType\": step},\n",
    "                backend_kwargs={\"errors\": \"ignore\"}\n",
    "            )\n",
    "        else:\n",
    "            ds = xr.open_dataset(\n",
    "                filename, \n",
    "                engine=\"cfgrib\", \n",
    "                filter_by_keys={\"typeOfLevel\": level}, \n",
    "                backend_kwargs={\"errors\": \"ignore\"}\n",
    "            )\n",
    "        # print key references if the return dataset is empty. ask users to recheck the filtering keys\n",
    "        if len(ds.data_vars) == 0:\n",
    "            print(\"The filter keys may be incorrect. Please check the following reference:\")\n",
    "            for i in key_details:\n",
    "                print(i)\n",
    "\n",
    "        return ds\n",
    "    \n",
    "    # ask users to recheck the file parameters if there is a 404 HTTP error\n",
    "    except HTTPError as err:\n",
    "        if err.code == 404:\n",
    "            print(f\"{URL} does not exist. Please check the parameters again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cycle_runtime`: the model cycle runtime (i.e. 00, 06, 12, 18)\\\n",
    "`forcast_hour` : the forecast hour of product from 000 - 384\\\n",
    "`year`, `month`, `day` : Azure container retains GFS data for 3 months\\\n",
    "`resolution_degree` : degree resolution of the data (i.e. 0.25, 0.5, 1.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# define variables to fetch yesterday's data for plotting purposes\n",
    "yesterday = datetime.now().day - 1\n",
    "current_month = datetime.now().month\n",
    "current_year = datetime.now().year\n",
    "\n",
    "URL = file_path(cycle_runtime=12, forecast_hour=102, year=current_year, month=current_month, day=yesterday, resolution_degree=.25)\n",
    "ds_yesterday = read_into_xarray_dataset(URL, 'pressureFromGroundLayer')\n",
    "\n",
    "print(URL)\n",
    "ds_yesterday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the dataset with US boundary, convert it into pandas dataframe, rename and reorder the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usa = (ds_yesterday[['t', 'r', 'q', 'u', 'v']]\n",
    "          .sel(latitude = slice(50, 24), longitude = slice(235, 293))\n",
    "          .to_dataframe()\n",
    "          .sort_values('latitude')\n",
    "          .reset_index()\n",
    "          )\n",
    "\n",
    "df_usa.rename(columns = {'t' : ds_yesterday['t'].standard_name, \n",
    "                         'r' : ds_yesterday['r'].standard_name, \n",
    "                         'q' : ds_yesterday['q'].standard_name, \n",
    "                         'u' : ds_yesterday['u'].standard_name, \n",
    "                         'v' : ds_yesterday['v'].standard_name}, inplace = True\n",
    "                         )\n",
    "\n",
    "df_usa.drop('valid_time', axis = 1, inplace = True)\n",
    "df_usa = df_usa.iloc[:, [7,8,9,0,1,2,3,4,5,6]]\n",
    "\n",
    "df_usa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "#### Loop through six different forecast hour periods to see global temperature changes with 1.00 degree resolution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: This process may take a while to run. Please be patient.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "# define a list of forecast hours \n",
    "forecast_hours = [x for x in range(12, 72 + 1, 12)]\n",
    "\n",
    "fig = plt.figure(figsize = (15, 12))\n",
    "rows = len(forecast_hours) // 2 + len(forecast_hours) % 2\n",
    "cols = 2\n",
    "\n",
    "# add alive bar to see the progrees for generating each subplots\n",
    "with alive_bar(len(forecast_hours), force_tty=True, title='Running', length=20, bar = 'smooth') as bar:\n",
    "    for n, forecast_hour in enumerate(forecast_hours):\n",
    "        URL = file_path(12, forecast_hour, current_year, current_month, yesterday, 1.)\n",
    "        ds = read_into_xarray_dataset(URL, 'pressureFromGroundLayer')\n",
    "        ax = plt.subplot(rows, cols, n + 1, projection=ccrs.Robinson())\n",
    "        ax.coastlines(resolution=\"10m\")\n",
    "        # convert temperature measurement from K to C\n",
    "        (ds['t'] - 273.15).plot(ax = ax,\n",
    "                                cmap=plt.cm.coolwarm,\n",
    "                                transform=ccrs.PlateCarree(), \n",
    "                                cbar_kwargs={\"shrink\": 0.6, \"label\": \"Temperature [C]\"}\n",
    "                                )\n",
    "        plt.title(f\"forecast {ds.step.values.astype('timedelta64[h]')}\")  \n",
    "        plt.grid(False)\n",
    "        bar()\n",
    "\n",
    "plt.suptitle(\"Three day forecast of Temperature from \" \n",
    "             f\"{ds.time.values.astype('datetime64[s]')} \" \n",
    "             \"with 1.00 degree resolution\", \n",
    "             size = 18\n",
    "             )\n",
    "\n",
    "plt.subplots_adjust(top = 0.95)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through all different resolution degrees to see the difference of picture clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: This process may take a while to run. Please be patient.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 18))\n",
    "\n",
    "resolution_degrees = [0.25, 0.5, 1.]\n",
    "\n",
    "with alive_bar(len(resolution_degrees), force_tty=True, title='Running', length=20, bar = 'smooth') as bar:\n",
    "    for n, resolution_degree in enumerate(resolution_degrees):\n",
    "        URL = file_path(12, 24, current_year, current_month, yesterday, resolution_degree)\n",
    "        ds = read_into_xarray_dataset(URL, 'pressureFromGroundLayer')\n",
    "        ax = plt.subplot(3, 1, n + 1)\n",
    "        ds['r'].plot(ax = ax)\n",
    "        plt.title(f\"forecast {ds.step.values.astype('timedelta64[h]')} \" \n",
    "                  f\"from {ds.time.values.astype('datetime64[s]')} \" \n",
    "                  f\"with {resolution_degree} degree resolution\"\n",
    "                  )\n",
    "        plt.grid(False)  \n",
    "        bar()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focusing on the United States, add states and borders using `cartopy.feature` to make it more aesthetically appealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.feature as cfeature\n",
    "\n",
    "fig = plt.figure(figsize = (15, 10))\n",
    "ds_usa = ds_yesterday.sel(latitude = slice(50, 20), longitude = slice(235, 294))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "(ds_usa['t'] - 273.15).plot.contourf(\n",
    "                            ax = ax,\n",
    "                            cmap = plt.cm.coolwarm,\n",
    "                            transform = ccrs.PlateCarree(), \n",
    "                            cbar_kwargs={\"shrink\": 0.6, \"label\": \"Temperature [C]\"}\n",
    "                            )\n",
    "ax.coastlines()\n",
    "ax.add_feature(cfeature.STATES.with_scale('10m'), zorder=3, linewidth=0.8, edgecolor='black')\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.8)\n",
    "\n",
    "plt.title(f\"forecast {ds_usa.step.values.astype('timedelta64[h]')} \" \n",
    "          f\"from {ds_usa.time.values.astype('datetime64[s]')} \" \n",
    "         )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focus on United States with 30 different meteorological variables  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: This process may take a while to run. Please be patient.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = file_path(cycle_runtime=12, forecast_hour=12, year=current_year, month=current_month, day=yesterday, resolution_degree=0.25)\n",
    "ds = read_into_xarray_dataset(URL, 'surface', 'instant')\n",
    "\n",
    "# filter out unknown data variable\n",
    "filtered_vars = [var for var in ds.data_vars if var != 'unknown']\n",
    "ds_usa = ds.sel(latitude = slice(50, 20), longitude = slice(235, 294))\n",
    "\n",
    "fig = plt.figure(figsize = (50, 80))\n",
    "cols = 3\n",
    "rows = len(filtered_vars) // cols + len(filtered_vars) % cols\n",
    "\n",
    "with alive_bar(len(filtered_vars), force_tty=True, title='Running', length=20, bar = 'smooth') as bar:\n",
    "    for n, var in enumerate(filtered_vars):\n",
    "        ax = plt.subplot(rows, cols, n + 1, projection=ccrs.PlateCarree())\n",
    "        ax.coastlines(resolution=\"10m\")\n",
    "        im = ds_usa[var].plot(ax = ax,\n",
    "                        transform=ccrs.PlateCarree(),\n",
    "                        add_colorbar=False \n",
    "                        )\n",
    "        cb = plt.colorbar(im)\n",
    "        cb.set_label(label=ds_usa[var].attrs['GRIB_units'], size=30)\n",
    "        cb.ax.tick_params(labelsize=20)\n",
    "        plt.title(f\"{ds_usa[var].attrs['long_name']}\", fontdict={'fontsize':40})  \n",
    "        plt.grid(False)\n",
    "        bar()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation - Temperature forecasting to 96 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "# create a folder `img` and store all the plots in it\n",
    "try:\n",
    "    os.mkdir('./img')\n",
    "except:\n",
    "    print('Directory already exists')\n",
    "\n",
    "# define a function to generate temperature plot per forecast hour\n",
    "def make_frame(forecast_hour:int):    \n",
    "    plt.figure(figsize=(15, 12))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "       \n",
    "    URL = file_path(12, forecast_hour, current_year, current_month, yesterday, 1.)\n",
    "    ds = read_into_xarray_dataset(URL, 'pressureFromGroundLayer')\n",
    "\n",
    "    ax = plt.axes(projection=ccrs.Robinson())\n",
    "    ax.coastlines(resolution=\"10m\")\n",
    "    (ds['t'] - 273.15).plot(ax = ax,\n",
    "                            cmap=plt.cm.coolwarm,\n",
    "                            transform=ccrs.PlateCarree(), \n",
    "                            cbar_kwargs={\"shrink\": 0.6, \"label\": \"Temperature [C]\"}\n",
    "                            )\n",
    "\n",
    "    plt.title(f\"Forecast {ds.step.values.astype('timedelta64[h]')} from {ds.time.values.astype('datetime64[s]')}\",  fontdict={'fontsize':18})  \n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'./img/temp_forecast_{forecast_hour}_hours.png', transparent=False, facecolor='white')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: This process may take a while to run.  It is the longest of the cells we are demonstrating. Please be patient.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plots with given forecast hours and save them into .png file\n",
    "forecast_hour = [x for x in range(3, 96 + 1, 3)]\n",
    "with alive_bar(len(forecast_hour), force_tty=True, title='Running', length=20, bar = 'smooth') as bar:\n",
    "    for t in forecast_hour:\n",
    "        make_frame(t)\n",
    "        bar()\n",
    "\n",
    "# use `imageio` to create gif with given plots \n",
    "frames = []\n",
    "for t in forecast_hour:\n",
    "    image = imageio.v2.imread(f'./img/temp_forecast_{t}_hours.png')\n",
    "    frames.append(image)\n",
    "\n",
    "imageio.mimsave('./img/temp_forecast.gif',\n",
    "                frames,\n",
    "                loop = 65535,\n",
    "                fps = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation - Relative Humidity forecasting to 96 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to generate relative humidity plot per forecast hour\n",
    "def make_frame(forecast_hour:int):\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "       \n",
    "    URL = file_path(12, forecast_hour, current_year, current_month, yesterday, 1.)\n",
    "    ds = read_into_xarray_dataset(URL, 'pressureFromGroundLayer')\n",
    "\n",
    "    ax = plt.axes(projection=ccrs.Robinson())\n",
    "    ax.coastlines(resolution=\"10m\")\n",
    "    \n",
    "    ds['r'].plot(ax = ax,\n",
    "                transform=ccrs.PlateCarree(), \n",
    "                cbar_kwargs={\"shrink\": 0.6}\n",
    "                )\n",
    "    \n",
    "    plt.title(f\"Forecast {ds.step.values.astype('timedelta64[h]')} from {ds.time.values.astype('datetime64[s]')}\", fontdict={'fontsize':18})  \n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'./img/relative_humidity_forecast_{forecast_hour}_hours.png', transparent=False, facecolor='white')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plots with given forecast hours and save them into .png file\n",
    "forecast_hour = [x for x in range(3, 96 + 1, 3)]\n",
    "with alive_bar(len(forecast_hour), force_tty=True, title='Running', length=20, bar = 'smooth') as bar:\n",
    "    for t in forecast_hour:\n",
    "        make_frame(t)\n",
    "        bar()\n",
    "\n",
    "# use `imageio` to create gif with given plots \n",
    "frames = []\n",
    "for t in forecast_hour:\n",
    "    image = imageio.v2.imread(f'./img/relative_humidity_forecast_{t}_hours.png')\n",
    "    frames.append(image)\n",
    "\n",
    "imageio.mimsave('./img/relative_humidity_forecast.gif',\n",
    "                frames,\n",
    "                loop = 65535,\n",
    "                fps = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
