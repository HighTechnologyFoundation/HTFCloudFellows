{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the speed of reading GFS data with 0.25 and 1.00 resolution degree into `Xarray dataset` from four sources: `NOMADS server` , `Azure Blob Storage` , `AWS S3 Bucket`, and `Google Cloud Storage` in local environment.\n",
    "\n",
    "### **Result**:\n",
    "|GFS Data|NOMADs|Azure|AWS|GCS|\n",
    "|----|----|-----|---|---|\n",
    "|1 file with 0.25 res|1 m 32 s|1 m 1 s  |51.8 s|51.1 s |\n",
    "|1 file with 1.00 res|7.09 s|5.27 s| 5.06 s |5.21 s  |\n",
    "|25 files with 0.25 res|34 m 7 s|24 m 3 s|21 m 5 s|23 m 22 s  |\n",
    "|25 files with 1.00 res|3 m 19 s|2 m 21 s |2 m 14 s|2 m 19 s |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import urllib.request\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240813'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use yesterday data from every sources for testing consistency\n",
    "yesterday = datetime.now() - timedelta(days = 1)\n",
    "yesterday = yesterday.strftime(\"%Y%m%d\")\n",
    "\n",
    "yesterday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.25 resolution degree = 515 MB / file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.94 s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "URL = f\"https://nomads.ncep.noaa.gov/pub/data/nccf/com/gfs/prod/gfs.{yesterday}/12/atmos/gfs.t12z.pgrb2.0p25.f108\"\n",
    "filename, _ = urllib.request.urlretrieve(URL)\n",
    "\n",
    "ds = xr.open_dataset(\n",
    "        filename,\n",
    "        engine=\"cfgrib\",\n",
    "        filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "        backend_kwargs={\"errors\": \"ignore\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.67 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "URL = f\"https://noaagfs.blob.core.windows.net/gfs/gfs.{yesterday}/12/atmos/gfs.t12z.pgrb2.0p25.f108\"\n",
    "\n",
    "filename, _ = urllib.request.urlretrieve(URL)\n",
    "ds = xr.open_dataset(\n",
    "        filename,\n",
    "        engine=\"cfgrib\",\n",
    "        filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "        backend_kwargs={\"errors\": \"ignore\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.56 s\n",
      "Wall time: 51.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "URL = f\"https://noaa-gfs-bdp-pds.s3.amazonaws.com/gfs.{yesterday}/12/atmos/gfs.t12z.pgrb2.0p25.f108\"\n",
    "\n",
    "filename, _ = urllib.request.urlretrieve(URL)\n",
    "ds = xr.open_dataset(\n",
    "        filename,\n",
    "        engine=\"cfgrib\",\n",
    "        filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "        backend_kwargs={\"errors\": \"ignore\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.69 s\n",
      "Wall time: 51.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "URL = f\"https://storage.googleapis.com/global-forecast-system/gfs.{yesterday}/12/atmos/gfs.t12z.pgrb2.0p25.f108\"\n",
    "\n",
    "filename, _ = urllib.request.urlretrieve(URL)\n",
    "ds = xr.open_dataset(\n",
    "        filename,\n",
    "        engine=\"cfgrib\",\n",
    "        filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "        backend_kwargs={\"errors\": \"ignore\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.00 resolution degree = 42.5 MB / file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 750 ms\n",
      "Wall time: 7.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "URL = f\"https://nomads.ncep.noaa.gov/pub/data/nccf/com/gfs/prod/gfs.{yesterday}/12/atmos/gfs.t12z.pgrb2.1p00.f108\"\n",
    "\n",
    "filename, _ = urllib.request.urlretrieve(URL)\n",
    "ds = xr.open_dataset(\n",
    "        filename,\n",
    "        engine=\"cfgrib\",\n",
    "        filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "        backend_kwargs={\"errors\": \"ignore\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 719 ms\n",
      "Wall time: 5.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "URL = f'https://noaagfs.blob.core.windows.net/gfs/gfs.{yesterday}/12/atmos/gfs.t12z.pgrb2.1p00.f108'\n",
    "\n",
    "filename, _ = urllib.request.urlretrieve(URL)\n",
    "ds = xr.open_dataset(\n",
    "        filename,\n",
    "        engine=\"cfgrib\",\n",
    "        filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "        backend_kwargs={\"errors\": \"ignore\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 344 ms\n",
      "Wall time: 5.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "URL = f\"https://noaa-gfs-bdp-pds.s3.amazonaws.com/gfs.{yesterday}/12/atmos/gfs.t12z.pgrb2.1p00.f108\"\n",
    "\n",
    "filename, _ = urllib.request.urlretrieve(URL)\n",
    "ds = xr.open_dataset(\n",
    "        filename,\n",
    "        engine=\"cfgrib\",\n",
    "        filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "        backend_kwargs={\"errors\": \"ignore\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 344 ms\n",
      "Wall time: 5.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "URL = f\"https://storage.googleapis.com/global-forecast-system/gfs.{yesterday}/12/atmos/gfs.t12z.pgrb2.1p00.f108\"\n",
    "\n",
    "filename, _ = urllib.request.urlretrieve(URL)\n",
    "ds = xr.open_dataset(\n",
    "        filename,\n",
    "        engine=\"cfgrib\",\n",
    "        filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "        backend_kwargs={\"errors\": \"ignore\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate 25 GFS file with 0.25 resolution degree (step: 0 - 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def file_path(source: str, cycle_runtime: int, forecast_hour: int, year: int, month: int, day: int, resolution_degree: float) -> str:\n",
    "    \n",
    "    if source == 'nomads':\n",
    "        prefix_path = \"https://nomads.ncep.noaa.gov/pub/data/nccf/com/gfs/prod/\"\n",
    "    elif source == 'az':\n",
    "        prefix_path = \"https://noaagfs.blob.core.windows.net/gfs/\"\n",
    "    elif source == 'aws':\n",
    "        prefix_path = \"https://noaa-gfs-bdp-pds.s3.amazonaws.com/\"\n",
    "    elif source == 'gcs':\n",
    "        prefix_path = \"https://storage.googleapis.com/global-forecast-system/\"\n",
    "\n",
    "    assert source in ['nomads', 'az', 'aws', 'gcs'], \"input source must be one of ['nomads', 'az', 'aws', 'gcs']\"\n",
    "\n",
    "    product_name = \"gfs\"\n",
    "    resolution_split = str(resolution_degree).split(\".\")\n",
    "\n",
    "    file_path = (\n",
    "        f\"{product_name}.{year}{month:>02}{day:>02}/\"\n",
    "        f\"{cycle_runtime:>02}/atmos/{product_name}.t{cycle_runtime:>02}z.\"\n",
    "        f\"pgrb2.{resolution_split[0]}p{resolution_split[1]:<02}.f{forecast_hour:>03}\"\n",
    "    )\n",
    "\n",
    "    whole_path = os.path.join(prefix_path, file_path)\n",
    "\n",
    "    return whole_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 26s\n",
      "Wall time: 34min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_list = []\n",
    "for i in range(0, 24 + 1):\n",
    "    URL = file_path(source='nomads', cycle_runtime=12, forecast_hour=i, year=int(yesterday[:4]), month=int(yesterday[4:6]), day=int(yesterday[6:8]), resolution_degree=.25)\n",
    "    filename, _ = urllib.request.urlretrieve(URL)\n",
    "    ds = xr.open_dataset(\n",
    "         filename,\n",
    "         engine=\"cfgrib\",\n",
    "         filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "         backend_kwargs={\"errors\": \"ignore\"}\n",
    "    )\n",
    "    ds_list.append(ds)\n",
    "\n",
    "ds_merged = xr.concat(ds_list,  dim='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_list = []\n",
    "for i in range(0, 24 + 1):\n",
    "    URL = file_path(source='az', cycle_runtime=12, forecast_hour=i, year=int(yesterday[:4]), month=int(yesterday[4:6]), day=int(yesterday[6:8]), resolution_degree=.25)\n",
    "    filename, _ = urllib.request.urlretrieve(URL)\n",
    "    ds = xr.open_dataset(\n",
    "         filename,\n",
    "         engine=\"cfgrib\",\n",
    "         filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "         backend_kwargs={\"errors\": \"ignore\"}\n",
    "    )\n",
    "    ds_list.append(ds)\n",
    "\n",
    "ds_merged = xr.concat(ds_list,  dim='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 25s\n",
      "Wall time: 21min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_list = []\n",
    "for i in range(0, 24 + 1):\n",
    "    URL = file_path(source='aws', cycle_runtime=12, forecast_hour=i, year=int(yesterday[:4]), month=int(yesterday[4:6]), day=int(yesterday[6:8]), resolution_degree=.25)\n",
    "    filename, _ = urllib.request.urlretrieve(URL)\n",
    "    ds = xr.open_dataset(\n",
    "         filename,\n",
    "         engine=\"cfgrib\",\n",
    "         filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "         backend_kwargs={\"errors\": \"ignore\"}\n",
    "    )\n",
    "    ds_list.append(ds)\n",
    "\n",
    "ds_merged = xr.concat(ds_list,  dim='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 18s\n",
      "Wall time: 23min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_list = []\n",
    "for i in range(0, 24 + 1):\n",
    "    URL = file_path(source='gcs', cycle_runtime=12, forecast_hour=i, year=int(yesterday[:4]), month=int(yesterday[4:6]), day=int(yesterday[6:8]), resolution_degree=.25)\n",
    "    filename, _ = urllib.request.urlretrieve(URL)\n",
    "    ds = xr.open_dataset(\n",
    "         filename,\n",
    "         engine=\"cfgrib\",\n",
    "         filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "         backend_kwargs={\"errors\": \"ignore\"}\n",
    "    )\n",
    "    ds_list.append(ds)\n",
    "\n",
    "ds_merged = xr.concat(ds_list,  dim='step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate 25 GFS file with 1.00 resolution degree (step: 0 - 72 with interval 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13.4 s\n",
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_list = []\n",
    "for i in range(0, 72 + 1, 3):\n",
    "    URL = file_path(source='nomads', cycle_runtime=12, forecast_hour=i, year=int(yesterday[:4]), month=int(yesterday[4:6]), day=int(yesterday[6:8]), resolution_degree=1.)\n",
    "    filename, _ = urllib.request.urlretrieve(URL)\n",
    "    ds = xr.open_dataset(\n",
    "         filename,\n",
    "         engine=\"cfgrib\",\n",
    "         filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "         backend_kwargs={\"errors\": \"ignore\"}\n",
    "    )\n",
    "    ds_list.append(ds)\n",
    "\n",
    "ds_merged = xr.concat(ds_list,  dim='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13.8 s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_list = []\n",
    "for i in range(0, 72 + 1, 3):\n",
    "    URL = file_path(source='az', cycle_runtime=12, forecast_hour=i, year=int(yesterday[:4]), month=int(yesterday[4:6]), day=int(yesterday[6:8]), resolution_degree=1.)\n",
    "    filename, _ = urllib.request.urlretrieve(URL)\n",
    "    ds = xr.open_dataset(\n",
    "         filename,\n",
    "         engine=\"cfgrib\",\n",
    "         filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "         backend_kwargs={\"errors\": \"ignore\"}\n",
    "    )\n",
    "    ds_list.append(ds)\n",
    "\n",
    "ds_merged = xr.concat(ds_list,  dim='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.2 s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_list = []\n",
    "for i in range(0, 72 + 1, 3):\n",
    "    URL = file_path(source='aws', cycle_runtime=12, forecast_hour=i, year=int(yesterday[:4]), month=int(yesterday[4:6]), day=int(yesterday[6:8]), resolution_degree=1.)\n",
    "    filename, _ = urllib.request.urlretrieve(URL)\n",
    "    ds = xr.open_dataset(\n",
    "         filename,\n",
    "         engine=\"cfgrib\",\n",
    "         filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "         backend_kwargs={\"errors\": \"ignore\"}\n",
    "    )\n",
    "    ds_list.append(ds)\n",
    "\n",
    "ds_merged = xr.concat(ds_list,  dim='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14 s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_list = []\n",
    "for i in range(0, 72 + 1, 3):\n",
    "    URL = file_path(source='gcs', cycle_runtime=12, forecast_hour=i, year=int(yesterday[:4]), month=int(yesterday[4:6]), day=int(yesterday[6:8]), resolution_degree=1.)\n",
    "    filename, _ = urllib.request.urlretrieve(URL)\n",
    "    ds = xr.open_dataset(\n",
    "         filename,\n",
    "         engine=\"cfgrib\",\n",
    "         filter_by_keys={'typeOfLevel': 'pressureFromGroundLayer'},\n",
    "         backend_kwargs={\"errors\": \"ignore\"}\n",
    "    )\n",
    "    ds_list.append(ds)\n",
    "\n",
    "ds_merged = xr.concat(ds_list,  dim='step')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
